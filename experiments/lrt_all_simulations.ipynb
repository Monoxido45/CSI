{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loforest and locart functions\n",
    "from CP2LFI.loforest import ConformalLoforest, tune_loforest_LFI\n",
    "from CP2LFI.scores import LambdaScore\n",
    "from CP2LFI.simulations import Simulations, naive, predict_naive_quantile\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from clover import LocartSplit\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing LRT for every model of choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting and comparing the performance of each method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_quantiles(\n",
    "    kind_model,\n",
    "    thetas,\n",
    "    N,\n",
    "    rng,\n",
    "    B=1000,\n",
    "    alpha=0.05,\n",
    "    min_samples_leaf=100,\n",
    "    n_estimators = 100,\n",
    "    K = 50,\n",
    "    naive_n=500\n",
    "):\n",
    "    # fitting and predicting naive\n",
    "    naive_quantiles = naive(stat = \"lrt\", kind_model = kind_model, alpha = alpha, rng = rng, B=B, N=N, naive_n= naive_n)\n",
    "    naive_list = predict_naive_quantile(kind_model, thetas, naive_quantiles)\n",
    "\n",
    "    # simulating to fit models\n",
    "    sim_obj = Simulations(rng=rng, kind_model=kind_model)\n",
    "    thetas_sim, model_lambdas = sim_obj.LRT_sample(B = B , N = N)\n",
    "\n",
    "    if thetas_sim.ndim == 1:\n",
    "        model_thetas = thetas_sim.reshape(-1, 1)\n",
    "    else:\n",
    "        model_thetas = thetas_sim\n",
    "\n",
    "    locart_object = LocartSplit(\n",
    "        LambdaScore, None, alpha=alpha, is_fitted=True, split_calib=False\n",
    "    )\n",
    "    locart_quantiles = locart_object.calib(\n",
    "        model_thetas, model_lambdas, min_samples_leaf=min_samples_leaf\n",
    "    )\n",
    "\n",
    "    # loforest quantiles\n",
    "    loforest_object = ConformalLoforest(\n",
    "        LambdaScore, None, alpha=alpha, is_fitted=True, split_calib=False\n",
    "    )\n",
    "    loforest_object.calibrate(\n",
    "        model_thetas, \n",
    "        model_lambdas, \n",
    "        min_samples_leaf=min_samples_leaf, \n",
    "        n_estimators= n_estimators,\n",
    "        K = K,\n",
    "    )\n",
    "\n",
    "    # boosting quantiles\n",
    "    model = HistGradientBoostingRegressor(\n",
    "        loss=\"quantile\",\n",
    "        max_iter=100,\n",
    "        max_depth=3,\n",
    "        quantile=1 - alpha,\n",
    "        random_state=105,\n",
    "        n_iter_no_change=15,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "    model.fit(model_thetas, model_lambdas)\n",
    "\n",
    "    if thetas.ndim == 1:\n",
    "        valid_thetas = thetas.reshape(-1, 1)\n",
    "    else:\n",
    "        valid_thetas = thetas\n",
    "\n",
    "    # locart quantiles\n",
    "    idxs = locart_object.cart.apply(valid_thetas)\n",
    "    list_locart_quantiles = [locart_quantiles[idx] for idx in idxs]\n",
    "\n",
    "    # loforest\n",
    "    loforest_cutoffs = loforest_object.compute_cutoffs(valid_thetas)\n",
    "\n",
    "    # boosting\n",
    "    boosting_quantiles = model.predict(valid_thetas)\n",
    "\n",
    "    # tuned loforest\n",
    "    arr = np.arange(30, 95, 5)\n",
    "    K_grid = np.concatenate(([0], arr))\n",
    "\n",
    "    K_loforest = tune_loforest_LFI(\n",
    "        loforest_object, valid_thetas, model_lambdas, K_grid=K_grid\n",
    "    )\n",
    "\n",
    "    loforest_cutoffs_tuned = loforest_object.compute_cutoffs(\n",
    "        valid_thetas, K=K_loforest\n",
    "    )\n",
    "\n",
    "    print(\"Tuned K: \", K_loforest)\n",
    "    # ks quantile\n",
    "    ks_quantiles = np.tile(stats.kstwobign.ppf(1 - alpha), thetas.shape[0])\n",
    "\n",
    "    # dictionary of quantiles\n",
    "    quantile_dict = {\n",
    "        \"naive\": naive_list,\n",
    "        \"locart\": list_locart_quantiles,\n",
    "        \"loforest\": loforest_cutoffs,\n",
    "        \"tuned_loforest\": loforest_cutoffs_tuned,\n",
    "        \"boosting\": boosting_quantiles,\n",
    "        \"ks\": ks_quantiles,\n",
    "    }\n",
    "\n",
    "    return quantile_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
