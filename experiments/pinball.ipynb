{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9542482-ab64-4ca1-aa6f-d7dd152d29b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56831574-dd29-49b9-9f85-d16a93735a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "err = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53e07c7",
   "metadata": {},
   "source": [
    "# First simulated example.\n",
    "\n",
    "Let $\\theta$ be the parameter of interest and $\\lambda(\\theta) = F(\\theta) - \\hat{F}(\\theta)$, $F$ being the cummulative distribution of an $\\text{exp}(1)$ and $\\hat{F}$ the empirical cumulative distribution the test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05336e1d-13c0-4dfa-8532-cfc86f83e090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# o df_melted que retorna é só para printar as distribuicoes dos \n",
    "# lambdas com histplots e ver que elas mudam conforme theta\n",
    "\n",
    "def generate_parameters(thetas, N, iters):\n",
    "    values = pd.DataFrame()\n",
    "    ## Parametros para arvore\n",
    "    lambdas = []\n",
    "    thetas_ = []\n",
    "    ##\n",
    "    for theta in thetas:\n",
    "        diff = []\n",
    "        theoretical = np.e**(-theta)\n",
    "        for i in range(iters):\n",
    "            exp = np.random.exponential(1/theta, N)\n",
    "            empirical = (len([i for i in exp if i > 1])/len(exp))\n",
    "            diff.append(abs(theoretical - empirical))\n",
    "            lambdas.append(abs(theoretical - empirical))\n",
    "            thetas_.append(theta)\n",
    "        values[f\"{theta}\"] = diff\n",
    "    df_melted = values.melt(var_name='theta')\n",
    "    \n",
    "    return lambdas, thetas_, df_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09236b91-774d-4dbd-ba19-882245cb07a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_coverage(quantiles):\n",
    "    # theta = parametro\n",
    "    # lambda = estatistica de teste\n",
    "    # Lambda: |P_teorica(exp > 1) - P_empirica(exp > 1)|\n",
    "    j = 0\n",
    "    err = 0\n",
    "    for theta in thetas:\n",
    "        theoretical = np.e**(-theta)\n",
    "        lambdas_ = []\n",
    "        for i in range(iters):\n",
    "            distr = np.random.exponential(1/theta, N)\n",
    "            empirical = len([i for i in distr if i > 1])/len(distr)\n",
    "            diff = abs(theoretical - empirical)\n",
    "            lambdas_.append(diff)\n",
    "        alpha = len([i for i in lambdas_ if i >= quantiles[j]])/len(lambdas_)\n",
    "        print(f\"alpha for theta={theta} : {alpha} --- quantile: {quantiles[j]}\")\n",
    "        err += abs(alpha - 0.05)\n",
    "        j += 1\n",
    "    print(f\"mean absolute error: {err/j}\")\n",
    "    return err/j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a951038-81e6-41da-a629-5f53525a88ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# isso foi usado em um experimento\n",
    "def params_with_random_thetas(thetas, N):\n",
    "    chosen_thetas = np.random.choice(thetas, N)\n",
    "    lambdas = []\n",
    "    thetas_ = []\n",
    "    ##\n",
    "    for theta in chosen_thetas:\n",
    "        theoretical = np.e**(-theta)\n",
    "        exp = np.random.exponential(1/theta, 10000)\n",
    "        empirical = len([i for i in exp if i > 1])/len(exp)\n",
    "        lambdas.append(abs(theoretical - empirical))\n",
    "        thetas_.append(theta)\n",
    "        \n",
    "    return lambdas, thetas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a5cf503b-9a5c-42a0-b518-f330e0661385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fica a vontade pra mudar isso aqui se quiser brincar\n",
    "thetas = np.arange(0.5, 7, 0.5)\n",
    "N = 10000\n",
    "iters = 10000\n",
    "\n",
    "np.random.seed(1250)\n",
    "lambdas, thetas_, df_melted = generate_parameters(thetas, N, iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621d8a68",
   "metadata": {},
   "source": [
    "*df_melted* is the dataset with simulated $\\lambda$ values for each value of $\\theta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0984018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.008069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.004569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.009131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.002969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  theta     value\n",
       "0   0.5  0.000369\n",
       "1   0.5  0.003531\n",
       "2   0.5  0.008069\n",
       "3   0.5  0.003431\n",
       "4   0.5  0.004531\n",
       "5   0.5  0.004569\n",
       "6   0.5  0.000669\n",
       "7   0.5  0.009131\n",
       "8   0.5  0.002969\n",
       "9   0.5  0.005231"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_melted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e3f71",
   "metadata": {},
   "source": [
    "We want to obtain, for each $\\theta$ a cutoff $C_{\\theta}$ to build:\n",
    "$$R(\\mathcal{D}) = \\{\\theta \\in \\Theta: \\lambda(\\theta, \\mathcal{D}) \\geq C_{\\theta} \\} ,$$\n",
    "such that:\n",
    "$$\\mathbb{P}_{\\mathcal{D}|\\theta}(\\theta \\in R(\\mathcal{D})) \\geq 1 - \\alpha \\quad \\forall \\theta \\in \\Theta.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2453580d-254b-48b0-a048-e73a45169372",
   "metadata": {},
   "source": [
    "# Naive estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ad1a0",
   "metadata": {},
   "source": [
    "Naive estimation of each cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8ab77fe2-97bd-4471-a11f-997bfe8c1733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# isso aqui eh o que eu to chamando de naive. Basicamente pega o\n",
    "# parametro e tira o quantil dele. usei o df_melted pq era mais facil\n",
    "# por algum motivo que nao consigo lembrar de cabeça agora\n",
    "naive = [\n",
    "    np.quantile(list(df_melted[df_melted[\"theta\"] == str(theta)].value), 0.95)\n",
    "    for theta in thetas\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "41339fa0-7179-426a-a379-5a62e8494963",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha for theta=0.5 : 0.055 --- quantile: 0.009530659712633449\n",
      "alpha for theta=1.0 : 0.0488 --- quantile: 0.009479441171442338\n",
      "alpha for theta=1.5 : 0.0497 --- quantile: 0.008230160148429838\n",
      "alpha for theta=2.0 : 0.0532 --- quantile: 0.0066352832366126935\n",
      "alpha for theta=2.5 : 0.0576 --- quantile: 0.005284998623898807\n",
      "alpha for theta=3.0 : 0.0517 --- quantile: 0.004312931632136051\n",
      "alpha for theta=3.5 : 0.0536 --- quantile: 0.003302616577681494\n",
      "alpha for theta=4.0 : 0.047 --- quantile: 0.0026843611112658157\n",
      "alpha for theta=4.5 : 0.0532 --- quantile: 0.002008996538242309\n",
      "alpha for theta=5.0 : 0.0512 --- quantile: 0.0016379469990854684\n",
      "alpha for theta=5.5 : 0.0596 --- quantile: 0.0012132285615359317\n",
      "alpha for theta=6.0 : 0.059 --- quantile: 0.0009787521766663593\n",
      "alpha for theta=6.5 : 0.0741 --- quantile: 0.000703439192977573\n",
      "mean absolute error: 0.00559230769230769\n"
     ]
    }
   ],
   "source": [
    "err[\"err_naive\"] = eval_coverage(naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754cb2ab-d07e-4cba-b9ce-8ab75d59dc55",
   "metadata": {},
   "source": [
    "# Pinball oriented Regression Tree\n",
    "Fitting a regression tree that uses the pinball loss for partitioning the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "13cb168e-b31b-4a2b-b909-d3a852026687",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuben45/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(alpha=0.95, learning_rate=0.2, loss=&#x27;huber&#x27;,\n",
       "                          min_samples_leaf=100, n_estimators=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(alpha=0.95, learning_rate=0.2, loss=&#x27;huber&#x27;,\n",
       "                          min_samples_leaf=100, n_estimators=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.95, learning_rate=0.2, loss='huber',\n",
       "                          min_samples_leaf=100, n_estimators=1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se colocar o boosting com 1 iteracao, ele vira uma arvore\n",
    "# e o quantile loss eh o pinball. ref: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html\n",
    "model = GradientBoostingRegressor(\n",
    "    loss = \"huber\", alpha = .95, learning_rate = 0.2, min_samples_leaf = 100, n_estimators = 1\n",
    ")\n",
    "\n",
    "model_thetas = np.array(thetas_).reshape(-1, 1)\n",
    "model_lambdas = np.array(lambdas).reshape(-1, 1)\n",
    "model.fit(model_thetas, model_lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7de1d1",
   "metadata": {},
   "source": [
    "testing first a locart way of obtaining the cutoffs (pinball-LOCART):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "56de6c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.],\n",
       "       [ 3.],\n",
       "       [ 4.],\n",
       "       [ 6.],\n",
       "       [ 7.],\n",
       "       [10.],\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [13.],\n",
       "       [13.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(thetas.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96f863a",
   "metadata": {},
   "source": [
    "Obtaining quantiles in the LOCART manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cb854bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves = np.unique(model.apply(thetas.reshape(-1, 1)))\n",
    "quantiles = {}\n",
    "for leaf in leaves:\n",
    "    indices = model.apply(model_thetas)\n",
    "    selected_lambdas = model_lambdas[indices == leaf]\n",
    "    n = selected_lambdas.shape[0]\n",
    "    quantiles[leaf]  = np.quantile(selected_lambdas, q=np.ceil((n + 1) * (1 - 0.05)) / n)\n",
    "idxs = model.apply(thetas.reshape(-1, 1))\n",
    "list_gb_quantiles = [quantiles[idx] for idx in idxs.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "724d6f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.009479441171442338,\n",
       " 0.009479441171442338,\n",
       " 0.008230160148429838,\n",
       " 0.0066352832366126935,\n",
       " 0.005284998623898807,\n",
       " 0.004312931632136051,\n",
       " 0.0030026165776814925,\n",
       " 0.0030026165776814925,\n",
       " 0.0018620530009145313,\n",
       " 0.0018620530009145313,\n",
       " 0.0010212478233336407,\n",
       " 0.0010212478233336407,\n",
       " 0.0010212478233336407]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_gb_quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c1eec",
   "metadata": {},
   "source": [
    "Obtaining errors for these quantiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c2736516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha for theta=0.5 : 0.0505 --- quantile: 0.009479441171442338\n",
      "alpha for theta=1.0 : 0.0503 --- quantile: 0.009479441171442338\n",
      "alpha for theta=1.5 : 0.0479 --- quantile: 0.008230160148429838\n",
      "alpha for theta=2.0 : 0.0557 --- quantile: 0.0066352832366126935\n",
      "alpha for theta=2.5 : 0.0564 --- quantile: 0.005284998623898807\n",
      "alpha for theta=3.0 : 0.0476 --- quantile: 0.004312931632136051\n",
      "alpha for theta=3.5 : 0.0783 --- quantile: 0.0030026165776814925\n",
      "alpha for theta=4.0 : 0.0228 --- quantile: 0.0030026165776814925\n",
      "alpha for theta=4.5 : 0.0768 --- quantile: 0.0018620530009145313\n",
      "alpha for theta=5.0 : 0.0247 --- quantile: 0.0018620530009145313\n",
      "alpha for theta=5.5 : 0.0974 --- quantile: 0.0010212478233336407\n",
      "alpha for theta=6.0 : 0.0458 --- quantile: 0.0010212478233336407\n",
      "alpha for theta=6.5 : 0.0069 --- quantile: 0.0010212478233336407\n",
      "mean absolute error: 0.016900000000000002\n"
     ]
    }
   ],
   "source": [
    "err[\"err_pinball_locart\"] = eval_coverage(list_gb_quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81962e96",
   "metadata": {},
   "source": [
    "testing now cutoffs obtained from direct predictions of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "da230e8a-2985-4328-895b-18e4d5ef63ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuben45/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00650547, 0.00650364, 0.00637939, 0.00621593, 0.00608091,\n",
       "       0.0059837 , 0.00588267, 0.00581397, 0.00569861, 0.00569861,\n",
       "       0.00569861, 0.00569861, 0.00569861])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HistGradientBoostingRegressor(\n",
    "    loss = \"quantile\", quantile = .95, min_samples_leaf = 100, max_iter=1\n",
    ")\n",
    "\n",
    "model_thetas = np.array(thetas_).reshape(-1, 1)\n",
    "model_lambdas = np.array(lambdas).reshape(-1, 1)\n",
    "model.fit(model_thetas, model_lambdas)\n",
    "\n",
    "quantiles = model.predict(thetas.reshape(-1, 1))\n",
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0b7518fd-8426-4b24-a27c-19b0f16ac443",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha for theta=0.5 : 0.1709 --- quantile: 0.006505472229893283\n",
      "alpha for theta=1.0 : 0.1772 --- quantile: 0.006503639788343396\n",
      "alpha for theta=1.5 : 0.1161 --- quantile: 0.006379390243786953\n",
      "alpha for theta=2.0 : 0.0712 --- quantile: 0.006215934582291208\n",
      "alpha for theta=2.5 : 0.0296 --- quantile: 0.006080906121019819\n",
      "alpha for theta=3.0 : 0.0064 --- quantile: 0.005983699421843543\n",
      "alpha for theta=3.5 : 0.0007 --- quantile: 0.005882667916398088\n",
      "alpha for theta=4.0 : 0.0 --- quantile: 0.005813970147503357\n",
      "alpha for theta=4.5 : 0.0 --- quantile: 0.005698611558721391\n",
      "alpha for theta=5.0 : 0.0 --- quantile: 0.005698611558721391\n",
      "alpha for theta=5.5 : 0.0 --- quantile: 0.005698611558721391\n",
      "alpha for theta=6.0 : 0.0 --- quantile: 0.005698611558721391\n",
      "alpha for theta=6.5 : 0.0 --- quantile: 0.005698611558721391\n",
      "mean absolute error: 0.057592307692307707\n"
     ]
    }
   ],
   "source": [
    "err[\"err_reg\"] = eval_coverage(quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387cac18",
   "metadata": {},
   "source": [
    "## Testing MSE-LOCART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5d780cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining new score using the Scores class, specifically for the df_melted dataset\n",
    "from clover import Scores\n",
    "from clover import LocartSplit\n",
    "\n",
    "class LambdaScore(Scores):\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def compute(self, thetas, lambdas):\n",
    "        return lambdas\n",
    "\n",
    "    def predict(self, thetas, cutoff):\n",
    "        pred = np.vstack((thetas - cutoff, thetas + cutoff)).T\n",
    "        return pred\n",
    "\n",
    "# fitting locart to the new synthetic class\n",
    "locart_object = LocartSplit(LambdaScore, None, alpha = 0.05, is_fitted = True, split_calib = False)\n",
    "locart_quantiles = locart_object.calib(model_thetas, model_lambdas)\n",
    "idxs = locart_object.cart.apply(thetas.reshape(-1, 1))\n",
    "list_locart_quantiles = [locart_quantiles[idx] for idx in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aa20d554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha for theta=0.5 : 0.0484 --- quantile: 0.009530659712633449\n",
      "alpha for theta=1.0 : 0.0516 --- quantile: 0.009479441171442338\n",
      "alpha for theta=1.5 : 0.05 --- quantile: 0.008230160148429838\n",
      "alpha for theta=2.0 : 0.0547 --- quantile: 0.0066352832366126935\n",
      "alpha for theta=2.5 : 0.0503 --- quantile: 0.005284998623898807\n",
      "alpha for theta=3.0 : 0.0445 --- quantile: 0.004312931632136051\n",
      "alpha for theta=3.5 : 0.0523 --- quantile: 0.003302616577681494\n",
      "alpha for theta=4.0 : 0.0475 --- quantile: 0.0026843611112658157\n",
      "alpha for theta=4.5 : 0.053 --- quantile: 0.002008996538242309\n",
      "alpha for theta=5.0 : 0.0514 --- quantile: 0.0016379469990854684\n",
      "alpha for theta=5.5 : 0.063 --- quantile: 0.0012132285615359317\n",
      "alpha for theta=6.0 : 0.0548 --- quantile: 0.0009787521766663593\n",
      "alpha for theta=6.5 : 0.0725 --- quantile: 0.000703439192977573\n",
      "mean absolute error: 0.00486153846153846\n"
     ]
    }
   ],
   "source": [
    "err[\"err_locart\"] = eval_coverage(list_locart_quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a6a694-24ef-4aad-a6c2-e6f7de22dfc7",
   "metadata": {},
   "source": [
    "## Regressor - random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177f0271",
   "metadata": {},
   "source": [
    "Generating 1000 random thetas from the grid to compute the metrics of both the gradient boosting tree and the MSE-locart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1c8016f5-0161-4717-9ce3-2746528e848b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# aqui, a gente gera N (=1000) thetas aleatoriamente entre\n",
    "# os possiveis valores do grid e computa as metricas\n",
    "lambdas_r, thetas_r = params_with_random_thetas(thetas, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe4849",
   "metadata": {},
   "source": [
    "Obtaining metrics first for the gradient boosting unique tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6da7a7b0-fe6f-412e-8ecb-cd8ba4f198a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuben45/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingRegressor(loss=&#x27;quantile&#x27;, max_iter=1, quantile=0.95)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(loss=&#x27;quantile&#x27;, max_iter=1, quantile=0.95)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingRegressor(loss='quantile', max_iter=1, quantile=0.95)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HistGradientBoostingRegressor(\n",
    "    loss=\"quantile\", quantile=.95, max_iter=1\n",
    ")\n",
    "\n",
    "model_thetas = np.array(thetas_r).reshape(-1, 1)\n",
    "model_lambdas = np.array(lambdas_r).reshape(-1, 1)\n",
    "model.fit(model_thetas, model_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "deed538c-e372-4116-b2be-53b652a7652a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00633479, 0.00631502, 0.0062397 , 0.00604401, 0.00606857,\n",
       "       0.0057016 , 0.0057016 , 0.0057016 , 0.0057016 , 0.0057016 ,\n",
       "       0.0057016 , 0.0057016 , 0.0057016 ])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles = model.predict(thetas.reshape(-1, 1))\n",
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d5812f10-db87-4129-85be-ec2daeb3a6fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha for theta=0.5 : 0.1925 --- quantile: 0.006334786563000806\n",
      "alpha for theta=1.0 : 0.1847 --- quantile: 0.006315015003451892\n",
      "alpha for theta=1.5 : 0.1302 --- quantile: 0.006239704576894481\n",
      "alpha for theta=2.0 : 0.0765 --- quantile: 0.0060440149270052125\n",
      "alpha for theta=2.5 : 0.0256 --- quantile: 0.0060685705779764555\n",
      "alpha for theta=3.0 : 0.0098 --- quantile: 0.00570160115277289\n",
      "alpha for theta=3.5 : 0.0005 --- quantile: 0.00570160115277289\n",
      "alpha for theta=4.0 : 0.0 --- quantile: 0.00570160115277289\n",
      "alpha for theta=4.5 : 0.0 --- quantile: 0.00570160115277289\n",
      "alpha for theta=5.0 : 0.0 --- quantile: 0.00570160115277289\n",
      "alpha for theta=5.5 : 0.0 --- quantile: 0.00570160115277289\n",
      "alpha for theta=6.0 : 0.0 --- quantile: 0.00570160115277289\n",
      "alpha for theta=6.5 : 0.0 --- quantile: 0.00570160115277289\n",
      "mean absolute error: 0.061384615384615406\n"
     ]
    }
   ],
   "source": [
    "err[\"err_reg_random\"] = eval_coverage(quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34979e13",
   "metadata": {},
   "source": [
    "Obtaining the metrics for locart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8c07feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting locart to the new synthetic class\n",
    "locart_object = LocartSplit(LambdaScore, None, alpha = 0.05, is_fitted = True, split_calib = False)\n",
    "locart_quantiles = locart_object.calib(model_thetas, model_lambdas)\n",
    "idxs = locart_object.cart.apply(thetas.reshape(-1, 1))\n",
    "list_locart_quantiles = [locart_quantiles[idx] for idx in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "911da415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha for theta=0.5 : 0.0637 --- quantile: 0.009139509270155511\n",
      "alpha for theta=1.0 : 0.0568 --- quantile: 0.009139509270155511\n",
      "alpha for theta=1.5 : 0.0283 --- quantile: 0.009139509270155511\n",
      "alpha for theta=2.0 : 0.082 --- quantile: 0.005926099837758356\n",
      "alpha for theta=2.5 : 0.0287 --- quantile: 0.005926099837758356\n",
      "alpha for theta=3.0 : 0.0068 --- quantile: 0.005926099837758356\n",
      "alpha for theta=3.5 : 0.0825 --- quantile: 0.0029886714560933983\n",
      "alpha for theta=4.0 : 0.0287 --- quantile: 0.0029886714560933983\n",
      "alpha for theta=4.5 : 0.004 --- quantile: 0.0029886714560933983\n",
      "alpha for theta=5.0 : 0.0777 --- quantile: 0.001438911239158631\n",
      "alpha for theta=5.5 : 0.0252 --- quantile: 0.001438911239158631\n",
      "alpha for theta=6.0 : 0.1062 --- quantile: 0.0008076645450902484\n",
      "alpha for theta=6.5 : 0.0281 --- quantile: 0.0008076645450902484\n",
      "mean absolute error: 0.0283923076923077\n"
     ]
    }
   ],
   "source": [
    "err[\"err_locart_random\"] = eval_coverage(list_locart_quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65280d1-7ffc-4810-a53f-062162e59acf",
   "metadata": {},
   "source": [
    "## 20 iters in each theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb48068f",
   "metadata": {},
   "source": [
    "Making less iterations for each theta and testing the gradient boosting, naive and so on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e28aaff1-67e1-43c0-8ec6-e49aff095024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Aqui foi uma tentativa de fazer poucas iteracoes em cima de cada theta,\n",
    "# que é algo mais proximo do que acontece na realidade\n",
    "lambdas_few, thetas_few, _ = generate_parameters(thetas, N, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "58b751fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2. ],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [2.5],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3. ],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [3.5],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4. ],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5. ],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [5.5],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6. ],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5],\n",
       "       [6.5]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d994af11-91e8-4edb-987f-3843176d976d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuben45/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingRegressor(loss=&#x27;quantile&#x27;, max_iter=1, quantile=0.95)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(loss=&#x27;quantile&#x27;, max_iter=1, quantile=0.95)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingRegressor(loss='quantile', max_iter=1, quantile=0.95)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HistGradientBoostingRegressor(\n",
    "    loss=\"quantile\", quantile=.95, max_iter=1\n",
    ")\n",
    "\n",
    "model_thetas = np.array(thetas_few).reshape(-1, 1)\n",
    "model_lambdas = np.array(lambdas_few).reshape(-1, 1)\n",
    "model.fit(model_thetas, model_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0bd893a1-0a6b-4674-9f4c-05494ce731de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00595127, 0.00627218, 0.00591232, 0.00561421, 0.00559368,\n",
       "       0.00528434, 0.00528434, 0.00528434, 0.00528434, 0.00528434,\n",
       "       0.00528434, 0.00528434, 0.00528434])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles = model.predict(thetas.reshape(-1, 1))\n",
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f4137675-c8ff-4508-ba50-4782bd948c70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha for theta=0.5 : 0.2121 --- quantile: 0.005951271655975811\n",
      "alpha for theta=1.0 : 0.1923 --- quantile: 0.006272180735542627\n",
      "alpha for theta=1.5 : 0.1538 --- quantile: 0.005912316616754129\n",
      "alpha for theta=2.0 : 0.104 --- quantile: 0.005614206521407959\n",
      "alpha for theta=2.5 : 0.0409 --- quantile: 0.0055936809062637075\n",
      "alpha for theta=3.0 : 0.0154 --- quantile: 0.005284337729609411\n",
      "alpha for theta=3.5 : 0.0025 --- quantile: 0.005284337729609411\n",
      "alpha for theta=4.0 : 0.0002 --- quantile: 0.005284337729609411\n",
      "alpha for theta=4.5 : 0.0 --- quantile: 0.005284337729609411\n",
      "alpha for theta=5.0 : 0.0 --- quantile: 0.005284337729609411\n",
      "alpha for theta=5.5 : 0.0 --- quantile: 0.005284337729609411\n",
      "alpha for theta=6.0 : 0.0 --- quantile: 0.005284337729609411\n",
      "alpha for theta=6.5 : 0.0 --- quantile: 0.005284337729609411\n",
      "mean absolute error: 0.06563076923076924\n"
     ]
    }
   ],
   "source": [
    "err[\"err_reg_few_iters\"] = eval_coverage(quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb453d",
   "metadata": {},
   "source": [
    "Testing also for MSE-locart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "57473b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting locart to the new synthetic class\n",
    "# changing minimal sample leaves to a new strategic value\n",
    "locart_object = LocartSplit(LambdaScore, None, alpha = 0.05, is_fitted = True, split_calib = False)\n",
    "locart_quantiles = locart_object.calib(model_thetas, model_lambdas, min_samples_leaf = 5)\n",
    "idxs = locart_object.cart.apply(thetas.reshape(-1, 1))\n",
    "list_locart_quantiles = [locart_quantiles[idx] for idx in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "96f2b31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha for theta=0.5 : 0.0214 --- quantile: 0.011365619094593767\n",
      "alpha for theta=1.0 : 0.0184 --- quantile: 0.011365619094593767\n",
      "alpha for theta=1.5 : 0.0083 --- quantile: 0.011365619094593767\n",
      "alpha for theta=2.0 : 0.0735 --- quantile: 0.006046244260783349\n",
      "alpha for theta=2.5 : 0.0262 --- quantile: 0.006046244260783349\n",
      "alpha for theta=3.0 : 0.1138 --- quantile: 0.0034275448175940036\n",
      "alpha for theta=3.5 : 0.0446 --- quantile: 0.0034275448175940036\n",
      "alpha for theta=4.0 : 0.0094 --- quantile: 0.0034275448175940036\n",
      "alpha for theta=4.5 : 0.0015 --- quantile: 0.0034275448175940036\n",
      "alpha for theta=5.0 : 0.0886 --- quantile: 0.0013695530009145325\n",
      "alpha for theta=5.5 : 0.0328 --- quantile: 0.0013695530009145325\n",
      "alpha for theta=6.0 : 0.0063 --- quantile: 0.0013695530009145325\n",
      "alpha for theta=6.5 : 0.0008 --- quantile: 0.0013695530009145325\n",
      "mean absolute error: 0.035092307692307693\n"
     ]
    }
   ],
   "source": [
    "err[\"err_locart_few\"] = eval_coverage(list_locart_quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e51429-86f3-4856-8c46-07f34ee93e9b",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1524efa5",
   "metadata": {},
   "source": [
    "Making use of the boosting algorithm to obtain the cutoff via a quantile regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "baca09bb-b6dd-4f2d-aa56-84975b2240d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuben45/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingRegressor(loss=&#x27;quantile&#x27;, quantile=0.95)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(loss=&#x27;quantile&#x27;, quantile=0.95)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingRegressor(loss='quantile', quantile=0.95)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HistGradientBoostingRegressor(\n",
    "    loss=\"quantile\", quantile=.95\n",
    ")\n",
    "\n",
    "model_thetas = np.array(thetas_).reshape(-1, 1)\n",
    "model_lambdas = np.array(lambdas).reshape(-1, 1)\n",
    "model.fit(model_thetas, model_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "de46fc41-6d51-48ae-9100-2afcba8aef22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "471ad427-e371-4d2d-9d50-2805f95e27f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00951491, 0.00950486, 0.0081604 , 0.00663296, 0.00528894,\n",
       "       0.00432138, 0.00331576, 0.00270037, 0.00202814, 0.00165534,\n",
       "       0.00123567, 0.00100505, 0.00073426])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosting_quantiles = model.predict(thetas.reshape(-1, 1))\n",
    "boosting_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e9bd46fd-3e1b-49a1-92d0-44444da392a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha for theta=0.5 : 0.0522 --- quantile: 0.009514910606241976\n",
      "alpha for theta=1.0 : 0.0504 --- quantile: 0.009504856574083537\n",
      "alpha for theta=1.5 : 0.0521 --- quantile: 0.008160402768874109\n",
      "alpha for theta=2.0 : 0.0531 --- quantile: 0.006632964037769399\n",
      "alpha for theta=2.5 : 0.0536 --- quantile: 0.00528894258207936\n",
      "alpha for theta=3.0 : 0.0496 --- quantile: 0.004321384423602406\n",
      "alpha for theta=3.5 : 0.0512 --- quantile: 0.0033157556121591555\n",
      "alpha for theta=4.0 : 0.0442 --- quantile: 0.0027003678604686204\n",
      "alpha for theta=4.5 : 0.0515 --- quantile: 0.0020281358969182293\n",
      "alpha for theta=5.0 : 0.042 --- quantile: 0.0016553416743011425\n",
      "alpha for theta=5.5 : 0.0491 --- quantile: 0.001235674120558699\n",
      "alpha for theta=6.0 : 0.0435 --- quantile: 0.0010050485890194464\n",
      "alpha for theta=6.5 : 0.044 --- quantile: 0.0007342571264241723\n",
      "mean absolute error: 0.003207692307692308\n"
     ]
    }
   ],
   "source": [
    "err[\"err_boosting\"] = eval_coverage(boosting_quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a5b83-d32f-4189-bc5d-05a1cd6857cf",
   "metadata": {},
   "source": [
    "## Random - Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42c7ac7",
   "metadata": {},
   "source": [
    "Repeating the random thetas experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "69bd686e-f4e6-4182-aeed-5a50c5255f62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# boosting com os parametros gerados aleatoriamente\n",
    "model_r = HistGradientBoostingRegressor(\n",
    "    loss=\"quantile\", quantile=.95\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9db7dd81-3989-485c-8a2e-5d23b1eb29ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuben45/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingRegressor(loss=&#x27;quantile&#x27;, quantile=0.95)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(loss=&#x27;quantile&#x27;, quantile=0.95)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingRegressor(loss='quantile', quantile=0.95)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_thetas = np.array(thetas_r).reshape(-1, 1)\n",
    "model_lambdas = np.array(lambdas_r).reshape(-1, 1)\n",
    "model_r.fit(model_thetas, model_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1f35a650-d1f5-4db3-80e2-030782deeda3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_r.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "37697f43-9928-4df9-9b50-45a5265735f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00914058, 0.00894287, 0.00818978, 0.00623294, 0.00647849,\n",
       "       0.00461665, 0.00340006, 0.0030394 , 0.00180907, 0.00145617,\n",
       "       0.00117344, 0.00094448, 0.00056116])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosting_quantiles_r = model_r.predict(thetas.reshape(-1, 1))\n",
    "boosting_quantiles_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c24ce317-c138-4a28-932f-b4204df377fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha for theta=0.5 : 0.057 --- quantile: 0.00914057690383788\n",
      "alpha for theta=1.0 : 0.06 --- quantile: 0.008942866559951539\n",
      "alpha for theta=1.5 : 0.0501 --- quantile: 0.008189782297880236\n",
      "alpha for theta=2.0 : 0.0673 --- quantile: 0.006232937776896031\n",
      "alpha for theta=2.5 : 0.0193 --- quantile: 0.00647848776428406\n",
      "alpha for theta=3.0 : 0.0374 --- quantile: 0.004616650655146988\n",
      "alpha for theta=3.5 : 0.0493 --- quantile: 0.0034000614403316563\n",
      "alpha for theta=4.0 : 0.0231 --- quantile: 0.0030393998005053646\n",
      "alpha for theta=4.5 : 0.0759 --- quantile: 0.0018090736622344364\n",
      "alpha for theta=5.0 : 0.0758 --- quantile: 0.0014561710521714614\n",
      "alpha for theta=5.5 : 0.0752 --- quantile: 0.0011734427000124885\n",
      "alpha for theta=6.0 : 0.0563 --- quantile: 0.000944478226890295\n",
      "alpha for theta=6.5 : 0.1592 --- quantile: 0.0005611568324452675\n",
      "mean absolute error: 0.022899999999999997\n"
     ]
    }
   ],
   "source": [
    "err[\"err_boosting_random\"] = eval_coverage(boosting_quantiles_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336724ce-ecb6-40b4-9986-bcb702dd02d0",
   "metadata": {},
   "source": [
    "## 20 iters in each theta - Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "223c2b70-1a85-4dc0-9f5d-3cac3f7b672c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuben45/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingRegressor(loss=&#x27;quantile&#x27;, quantile=0.95)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(loss=&#x27;quantile&#x27;, quantile=0.95)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingRegressor(loss='quantile', quantile=0.95)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# boosting com poucas observacoes sobre cada theta\n",
    "model = HistGradientBoostingRegressor(\n",
    "    loss=\"quantile\", quantile=.95,\n",
    ")\n",
    "\n",
    "model_thetas = np.array(thetas_few).reshape(-1, 1)\n",
    "model_lambdas = np.array(lambdas_few).reshape(-1, 1)\n",
    "model.fit(model_thetas, model_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8cb0b32e-be25-4501-889b-123157b85c28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8ade981b-9679-4cc0-bad4-b0cd8d81a6aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00919342, 0.01239099, 0.00882378, 0.00577641, 0.00558608,\n",
       "       0.00492352, 0.00278027, 0.00265441, 0.00274259, 0.0017383 ,\n",
       "       0.00150412, 0.00130084, 0.00072386])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles = model.predict(thetas.reshape(-1, 1))\n",
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "34448b1b-5d4e-4a95-b23a-ceef30fd92e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha for theta=0.5 : 0.0622 --- quantile: 0.00919342425185533\n",
      "alpha for theta=1.0 : 0.0112 --- quantile: 0.012390993913237138\n",
      "alpha for theta=1.5 : 0.0342 --- quantile: 0.00882378180140067\n",
      "alpha for theta=2.0 : 0.0897 --- quantile: 0.005776413735249767\n",
      "alpha for theta=2.5 : 0.0421 --- quantile: 0.005586083816467919\n",
      "alpha for theta=3.0 : 0.0237 --- quantile: 0.004923517746358238\n",
      "alpha for theta=3.5 : 0.11 --- quantile: 0.0027802676585627034\n",
      "alpha for theta=4.0 : 0.0482 --- quantile: 0.002654408301393961\n",
      "alpha for theta=4.5 : 0.0095 --- quantile: 0.002742594277357665\n",
      "alpha for theta=5.0 : 0.0315 --- quantile: 0.001738301331363586\n",
      "alpha for theta=5.5 : 0.0203 --- quantile: 0.0015041194997289955\n",
      "alpha for theta=6.0 : 0.0086 --- quantile: 0.0013008423245348634\n",
      "alpha for theta=6.5 : 0.0549 --- quantile: 0.0007238562075916346\n",
      "mean absolute error: 0.025961538461538463\n"
     ]
    }
   ],
   "source": [
    "err[\"err_boosting_few_iters\"] = eval_coverage(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a40f1c8a-a7e8-4aa7-8d3f-a3b3a0f6e1e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err_naive = 0.00559230769230769\n",
      "err_pinball_locart = 0.016900000000000002\n",
      "err_reg = 0.057592307692307707\n",
      "err_locart = 0.00486153846153846\n",
      "err_reg_random = 0.061384615384615406\n",
      "err_locart_random = 0.0283923076923077\n",
      "err_reg_few_iters = 0.06563076923076924\n",
      "err_locart_few = 0.035092307692307693\n",
      "err_boosting = 0.003207692307692308\n",
      "err_boosting_random = 0.022899999999999997\n",
      "err_boosting_few_iters = 0.025961538461538463\n"
     ]
    }
   ],
   "source": [
    "for key, value in err.items():\n",
    "    print(f\"{key} = {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
