{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLCP (tractable) experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all packages\n",
    "# normalizing flows packages\n",
    "import torch\n",
    "from torch.distributions.beta import Beta\n",
    "\n",
    "# loforest and locart functions\n",
    "from CP2LFI.loforest import ConformalLoforest, tune_loforest_LFI\n",
    "from CP2LFI.scores import Scores, LambdaScore, WaldoScore, BFFScore, E_valueScore\n",
    "from CP2LFI.posterior_models import normflow_posterior\n",
    "from clover import LocartSplit\n",
    "\n",
    "# quantile regression\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# plotting and numpy\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "# utils functions\n",
    "from CP2LFI.utils import obtain_quantiles, fit_post_model\n",
    "\n",
    "# package to simulate from tractable\n",
    "from hypothesis.benchmark import tractable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing MAE for a single N and B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute MAE for a single N and B\n",
    "def compute_MAE_N_B(\n",
    "    kind,\n",
    "    score,\n",
    "    theta_grid_eval,\n",
    "    simulator,\n",
    "    prior,\n",
    "    N = 5,\n",
    "    B = 10000,\n",
    "    alpha=0.05,\n",
    "    min_samples_leaf = 300,\n",
    "    n_estimators = 200,\n",
    "    K = 50,\n",
    "    B_valid= 500,\n",
    "    N_lambda = 250,\n",
    "    K_grid= np.concatenate((np.array([0]), np.arange(15, 95, 5))),\n",
    "    naive_n=500,\n",
    "    disable_tqdm = True,\n",
    "    seed = 45,\n",
    "    n_lambda = 300,\n",
    "    log_transf = False,\n",
    "    split_calib = False,\n",
    "    using_beta = False,\n",
    "):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    quantiles_dict = obtain_quantiles(\n",
    "    kind = kind, \n",
    "    score = score, \n",
    "    theta_grid_eval = theta_grid_eval, \n",
    "    simulator = simulator,\n",
    "    prior = prior, \n",
    "    N = N, \n",
    "    B = B, \n",
    "    alpha = alpha, \n",
    "    min_samples_leaf = min_samples_leaf, \n",
    "    n_estimators = n_estimators, \n",
    "    K = K,\n",
    "    disable_tqdm = disable_tqdm,\n",
    "    B_valid = B_valid,\n",
    "    N_lambda= N_lambda,\n",
    "    K_grid = K_grid,\n",
    "    naive_n = naive_n,\n",
    "    log_transf = log_transf,\n",
    "    split_calib = split_calib,\n",
    "    using_beta = using_beta,\n",
    ")\n",
    "    mae_list, se_list, methods_list, N_list, B_list = [], [], [], [], []\n",
    "    err_data = np.zeros((theta_grid_eval.shape[0], 5))\n",
    "    l = 0\n",
    "    for theta in tqdm(theta_grid_eval, desc = \"Evaluating coverage in this setting\"):\n",
    "        if theta_grid_eval.ndim == 1:\n",
    "            theta_repeated = torch.tensor([theta]).reshape(1, -1).repeat_interleave(repeats = n_lambda*N, dim = 0)\n",
    "        else:\n",
    "            theta_repeated = torch.tensor([theta]).repeat_interleave(repeats = n_lambda*N, dim = 0)\n",
    "            \n",
    "        # simulating lambdas for testing\n",
    "        X_net = simulator(theta_repeated)\n",
    "        if log_transf:\n",
    "            X_net = torch.log(X_net)\n",
    "        X_dim = X_net.shape[1]\n",
    "        X_net = X_net.reshape(n_lambda, N * X_dim)\n",
    "\n",
    "        stat = score.compute(theta_repeated.numpy()[0:n_lambda, :], X_net.numpy(), disable_tqdm = True)\n",
    "                \n",
    "        # comparing coverage of methods\n",
    "        locart_cover = np.mean(stat <= quantiles_dict[\"locart\"][l])\n",
    "        loforest_cover = np.mean(stat <= quantiles_dict[\"loforest_fixed\"][l])\n",
    "        loforest_tuned_cover = np.mean(stat <= quantiles_dict[\"loforest_tuned\"][l])\n",
    "        boosting_cover = np.mean(stat <= quantiles_dict[\"boosting\"][l])\n",
    "        naive_cover = np.mean(stat <= quantiles_dict[\"naive\"][l])\n",
    "\n",
    "        # appending the errors\n",
    "        err_locart = np.abs(locart_cover - (1 - alpha))\n",
    "        err_loforest = np.abs(loforest_cover - (1 - alpha))\n",
    "        err_loforest_tuned = np.abs(loforest_tuned_cover - (1 - alpha))\n",
    "        err_boosting = np.abs(boosting_cover - (1 - alpha))\n",
    "        err_naive = np.abs(naive_cover - (1 - alpha))\n",
    "        \n",
    "            # saving in numpy array\n",
    "        err_data[l, :] = np.array([err_locart, err_loforest, err_loforest_tuned, err_boosting, err_naive])\n",
    "        l += 1\n",
    "\n",
    "    mae_list.extend(np.mean(err_data, axis=0).tolist())\n",
    "    se_list.extend((np.std(err_data, axis=0) / np.sqrt(theta_grid_eval.shape[0])).tolist())\n",
    "    methods_list.extend([\"LOCART\", \"LOFOREST\", \"tuned LOFOREST\", \"boosting\", \"monte-carlo\"])\n",
    "    N_list.extend([N] * 5)\n",
    "    B_list.extend([B] * 5)\n",
    "\n",
    "    stats_data = pd.DataFrame(\n",
    "        {\n",
    "            \"methods\": methods_list,\n",
    "            \"N\": N_list,\n",
    "            \"B\": B_list,\n",
    "            \"MAE\": mae_list,\n",
    "            \"se\": se_list,\n",
    "        }\n",
    "    )\n",
    "    return stats_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining simulator and evaluation grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = tractable.Simulator()\n",
    "prior = tractable.Prior()\n",
    "\n",
    "# tractable grid\n",
    "n_par = 5\n",
    "pars = np.linspace(-2.9, 2.9, n_par)\n",
    "pars[pars == 0] = 0.01\n",
    "thetas_valid = np.c_[list(itertools.product(pars, pars, pars, pars, pars))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting posterior model for $n = 5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting normalizing flows posterior estimator:   3%|â–Ž         | 149/5000 [00:31<17:05,  4.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nflow_post_tractable \u001b[38;5;241m=\u001b[39m fit_post_model(\n\u001b[1;32m      2\u001b[0m     simulator \u001b[38;5;241m=\u001b[39m simulator, \n\u001b[1;32m      3\u001b[0m     prior \u001b[38;5;241m=\u001b[39m prior, \n\u001b[1;32m      4\u001b[0m     B_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20000\u001b[39m, \n\u001b[1;32m      5\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, \n\u001b[1;32m      6\u001b[0m     seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \n\u001b[1;32m      7\u001b[0m     split_seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m125\u001b[39m, \n\u001b[1;32m      8\u001b[0m     patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m      9\u001b[0m     n_flows \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     10\u001b[0m     log_transf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m     n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m,\n\u001b[1;32m     12\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/CP2LFI/utils.py:428\u001b[0m, in \u001b[0;36mfit_post_model\u001b[0;34m(simulator, prior, log_transf, B_model, n, seed, split_seed, n_flows, hidden_units, hidden_layers, enable_cuda, patience, n_epochs, batch_size, type_flow, plot_history, two_moons)\u001b[0m\n\u001b[1;32m    418\u001b[0m     thetas \u001b[38;5;241m=\u001b[39m thetas\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    419\u001b[0m nflow_post \u001b[38;5;241m=\u001b[39m normflow_posterior(\n\u001b[1;32m    420\u001b[0m     latent_size\u001b[38;5;241m=\u001b[39mthetas\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    421\u001b[0m     sample_size\u001b[38;5;241m=\u001b[39mX_net\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     enable_cuda\u001b[38;5;241m=\u001b[39menable_cuda,\n\u001b[1;32m    426\u001b[0m )\n\u001b[0;32m--> 428\u001b[0m nflow_post\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    429\u001b[0m     X_net\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m    430\u001b[0m     thetas\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m    431\u001b[0m     patience\u001b[38;5;241m=\u001b[39mpatience,\n\u001b[1;32m    432\u001b[0m     n_epochs\u001b[38;5;241m=\u001b[39mn_epochs,\n\u001b[1;32m    433\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    434\u001b[0m     split_seed\u001b[38;5;241m=\u001b[39msplit_seed,\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtype_flow,\n\u001b[1;32m    436\u001b[0m )\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plot_history:\n\u001b[1;32m    438\u001b[0m     nflow_post\u001b[38;5;241m.\u001b[39mplot_history()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/CP2LFI/posterior_models.py:201\u001b[0m, in \u001b[0;36mnormflow_posterior.fit\u001b[0;34m(self, X, theta, val_size, n_epochs, patience, batch_size, learning_rate, weight_decay, fix_seed, torch_seed, split_seed, type, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 201\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mforward_kld(x, context)\n\u001b[1;32m    202\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    203\u001b[0m     loss_val_list\u001b[38;5;241m.\u001b[39mappend(loss_value)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/normflows/core.py:333\u001b[0m, in \u001b[0;36mConditionalNormalizingFlow.forward_kld\u001b[0;34m(self, x, context)\u001b[0m\n\u001b[1;32m    331\u001b[0m z \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflows) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 333\u001b[0m     z, log_det \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflows[i]\u001b[38;5;241m.\u001b[39minverse(z, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m    334\u001b[0m     log_q \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m log_det\n\u001b[1;32m    335\u001b[0m log_q \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq0\u001b[38;5;241m.\u001b[39mlog_prob(z, context\u001b[38;5;241m=\u001b[39mcontext)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/normflows/flows/neural_spline/wrapper.py:235\u001b[0m, in \u001b[0;36mAutoregressiveRationalQuadraticSpline.inverse\u001b[0;34m(self, z, context)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, z, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 235\u001b[0m     z, log_det \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmprqat(z, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m z, log_det\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1675\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1669\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1674\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1677\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nflow_post_tractable = fit_post_model(\n",
    "    simulator = simulator, \n",
    "    prior = prior, \n",
    "    B_model = 20000, \n",
    "    n = 5, \n",
    "    seed = 0, \n",
    "    split_seed = 125, \n",
    "    patience = 200,\n",
    "    n_flows = 4,\n",
    "    log_transf = False,\n",
    "    n_epochs = 5000,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CP2LFI.scores.E_valueScore at 0x7fc52ca24910>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining scores\n",
    "# waldo score\n",
    "waldo_score = WaldoScore(nflow_post_tractable, is_fitted = True)\n",
    "waldo_score.fit()\n",
    "\n",
    "# BFF score\n",
    "bff_score = BFFScore(nflow_post_tractable, is_fitted = True)\n",
    "bff_score.fit()\n",
    "\n",
    "# e-value score\n",
    "e_value_score = E_valueScore(nflow_post_tractable, is_fitted = True)\n",
    "e_value_score.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing all models for $n = 5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering a beta prior over the calibration set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running naive method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fitting monte carlo cutoffs: 32it [00:35,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.0400051e-02 -5.8085228e-05 -7.1775816e-02 ... -4.0158696e-02\n",
      " -4.1234441e-04 -5.6458740e-03]\n",
      "Running all the other methods\n",
      "Obtaining tuning sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating all tuning sample: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [16:21<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting tuned loforest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating coverage in this setting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3125/3125 [29:56<00:00,  1.74it/s]\n"
     ]
    }
   ],
   "source": [
    "bff_stats_tractable_beta = compute_MAE_N_B(\n",
    "    kind = \"tractable\", \n",
    "    score = bff_score, \n",
    "    theta_grid_eval = thetas_valid, \n",
    "    simulator = simulator, \n",
    "    prior = prior, \n",
    "    N = 5, \n",
    "    B = 10000, \n",
    "    B_valid = 1000, \n",
    "    N_lambda = 500,\n",
    "    seed = 125,\n",
    "    K = 70,\n",
    "    n_estimators = 200,\n",
    "    min_samples_leaf = 300,\n",
    "    log_transf = False,\n",
    "    split_calib = False,\n",
    "    using_beta = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>methods</th>\n",
       "      <th>N</th>\n",
       "      <th>B</th>\n",
       "      <th>MAE</th>\n",
       "      <th>se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOCART</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.034612</td>\n",
       "      <td>0.000365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOFOREST</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.033534</td>\n",
       "      <td>0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tuned LOFOREST</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.032694</td>\n",
       "      <td>0.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boosting</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.039493</td>\n",
       "      <td>0.000586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>monte-carlo</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.046561</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          methods  N      B       MAE        se\n",
       "0          LOCART  5  10000  0.034612  0.000365\n",
       "1        LOFOREST  5  10000  0.033534  0.000351\n",
       "2  tuned LOFOREST  5  10000  0.032694  0.000337\n",
       "3        boosting  5  10000  0.039493  0.000586\n",
       "4     monte-carlo  5  10000  0.046561  0.000138"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bff_stats_tractable_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "second, for WALDO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running naive method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fitting monte carlo cutoffs: 32it [36:01, 67.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.8245938   4.91144633  6.41579278 ...  3.94845991  7.20265888\n",
      " 10.86673745]\n",
      "Running all the other methods\n",
      "Obtaining tuning sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating all tuning sample: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [1:33:50<00:00, 18.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting tuned loforest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating coverage in this setting:  20%|â–ˆâ–ˆ        | 633/3125 [6:49:28<26:52:01, 38.81s/it]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m waldo_stats_tractable_beta \u001b[38;5;241m=\u001b[39m compute_MAE_N_B(\n\u001b[1;32m      2\u001b[0m     kind \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtractable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      3\u001b[0m     score \u001b[38;5;241m=\u001b[39m waldo_score, \n\u001b[1;32m      4\u001b[0m     theta_grid_eval \u001b[38;5;241m=\u001b[39m thetas_valid, \n\u001b[1;32m      5\u001b[0m     simulator \u001b[38;5;241m=\u001b[39m simulator, \n\u001b[1;32m      6\u001b[0m     prior \u001b[38;5;241m=\u001b[39m prior, \n\u001b[1;32m      7\u001b[0m     N \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, \n\u001b[1;32m      8\u001b[0m     B \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m, \n\u001b[1;32m      9\u001b[0m     B_valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m, \n\u001b[1;32m     10\u001b[0m     N_lambda \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m150\u001b[39m,\n\u001b[1;32m     11\u001b[0m     seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m125\u001b[39m,\n\u001b[1;32m     12\u001b[0m     K \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m70\u001b[39m,\n\u001b[1;32m     13\u001b[0m     n_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m250\u001b[39m,\n\u001b[1;32m     14\u001b[0m     min_samples_leaf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m250\u001b[39m,\n\u001b[1;32m     15\u001b[0m     log_transf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m     split_calib \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m     using_beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[2], line 65\u001b[0m, in \u001b[0;36mcompute_MAE_N_B\u001b[0;34m(kind, score, theta_grid_eval, simulator, prior, N, B, alpha, min_samples_leaf, n_estimators, K, B_valid, N_lambda, K_grid, naive_n, disable_tqdm, seed, n_lambda, log_transf, split_calib, using_beta)\u001b[0m\n\u001b[1;32m     62\u001b[0m X_dim \u001b[38;5;241m=\u001b[39m X_net\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     63\u001b[0m X_net \u001b[38;5;241m=\u001b[39m X_net\u001b[38;5;241m.\u001b[39mreshape(n_lambda, N \u001b[38;5;241m*\u001b[39m X_dim)\n\u001b[0;32m---> 65\u001b[0m stat \u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39mcompute(theta_repeated\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m:n_lambda, :], X_net\u001b[38;5;241m.\u001b[39mnumpy(), disable_tqdm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# comparing coverage of methods\u001b[39;00m\n\u001b[1;32m     68\u001b[0m locart_cover \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(stat \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m quantiles_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocart\u001b[39m\u001b[38;5;124m\"\u001b[39m][l])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/CP2LFI/scores.py:153\u001b[0m, in \u001b[0;36mWaldoScore.compute\u001b[0;34m(self, thetas, X, N, one_sample, disable_tqdm)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m theta \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m    147\u001b[0m     thetas,\n\u001b[1;32m    148\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing waldo statistics using posterior model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    149\u001b[0m     disable\u001b[38;5;241m=\u001b[39mdisable_tqdm,\n\u001b[1;32m    150\u001b[0m ):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m one_sample:\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;66;03m# simulating from the model\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39msample(X\u001b[38;5;241m=\u001b[39mX[i, :], num_samples\u001b[38;5;241m=\u001b[39mN)\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;66;03m# computing E[theta|X]\u001b[39;00m\n\u001b[1;32m    156\u001b[0m         mean_theta_X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(s, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/CP2LFI/posterior_models.py:290\u001b[0m, in \u001b[0;36mnormflow_posterior.sample\u001b[0;34m(self, X, num_samples, fix_seed, random_state)\u001b[0m\n\u001b[1;32m    287\u001b[0m     X_s \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 290\u001b[0m     sample, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msample(context\u001b[38;5;241m=\u001b[39mX_s, num_samples\u001b[38;5;241m=\u001b[39mnum_samples)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sample\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/normflows/core.py:298\u001b[0m, in \u001b[0;36mConditionalNormalizingFlow.sample\u001b[0;34m(self, num_samples, context)\u001b[0m\n\u001b[1;32m    296\u001b[0m z, log_q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq0(num_samples, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m flow \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflows:\n\u001b[0;32m--> 298\u001b[0m     z, log_det \u001b[38;5;241m=\u001b[39m flow(z, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m    299\u001b[0m     log_q \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m log_det\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z, log_q\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/normflows/flows/neural_spline/wrapper.py:231\u001b[0m, in \u001b[0;36mAutoregressiveRationalQuadraticSpline.forward\u001b[0;34m(self, z, context)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, z, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 231\u001b[0m     z, log_det \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmprqat\u001b[38;5;241m.\u001b[39minverse(z, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m z, log_det\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/normflows/flows/affine/autoregressive.py:35\u001b[0m, in \u001b[0;36mAutoregressive.inverse\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_inputs):\n\u001b[1;32m     34\u001b[0m     autoregressive_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoregressive_net(outputs, context)\n\u001b[0;32m---> 35\u001b[0m     outputs, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elementwise_inverse(\n\u001b[1;32m     36\u001b[0m         inputs, autoregressive_params\n\u001b[1;32m     37\u001b[0m     )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, logabsdet\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/normflows/flows/neural_spline/autoregressive.py:134\u001b[0m, in \u001b[0;36mMaskedPiecewiseRationalQuadraticAutoregressive._elementwise_inverse\u001b[0;34m(self, inputs, autoregressive_params)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_elementwise_inverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, autoregressive_params):\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elementwise(inputs, autoregressive_params, inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/normflows/flows/neural_spline/autoregressive.py:116\u001b[0m, in \u001b[0;36mMaskedPiecewiseRationalQuadraticAutoregressive._elementwise\u001b[0;34m(self, inputs, autoregressive_params, inverse)\u001b[0m\n\u001b[1;32m    113\u001b[0m     spline_fn \u001b[38;5;241m=\u001b[39m splines\u001b[38;5;241m.\u001b[39munconstrained_rational_quadratic_spline\n\u001b[1;32m    114\u001b[0m     spline_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtails\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtails, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtail_bound\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtail_bound}\n\u001b[0;32m--> 116\u001b[0m outputs, logabsdet \u001b[38;5;241m=\u001b[39m spline_fn(\n\u001b[1;32m    117\u001b[0m     inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    118\u001b[0m     unnormalized_widths\u001b[38;5;241m=\u001b[39munnormalized_widths,\n\u001b[1;32m    119\u001b[0m     unnormalized_heights\u001b[38;5;241m=\u001b[39munnormalized_heights,\n\u001b[1;32m    120\u001b[0m     unnormalized_derivatives\u001b[38;5;241m=\u001b[39munnormalized_derivatives,\n\u001b[1;32m    121\u001b[0m     inverse\u001b[38;5;241m=\u001b[39minverse,\n\u001b[1;32m    122\u001b[0m     min_bin_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_bin_width,\n\u001b[1;32m    123\u001b[0m     min_bin_height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_bin_height,\n\u001b[1;32m    124\u001b[0m     min_derivative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_derivative,\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mspline_kwargs\n\u001b[1;32m    126\u001b[0m )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, utils\u001b[38;5;241m.\u001b[39msum_except_batch(logabsdet)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/normflows/utils/splines.py:76\u001b[0m, in \u001b[0;36munconstrained_rational_quadratic_spline\u001b[0;34m(inputs, unnormalized_widths, unnormalized_heights, unnormalized_derivatives, inverse, tails, tail_bound, min_bin_width, min_bin_height, min_derivative)\u001b[0m\n\u001b[1;32m     70\u001b[0m     bottom \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtail_bound\n\u001b[1;32m     71\u001b[0m     top \u001b[38;5;241m=\u001b[39m tail_bound\n\u001b[1;32m     73\u001b[0m (\n\u001b[1;32m     74\u001b[0m     outputs_masked,\n\u001b[1;32m     75\u001b[0m     logabsdet_masked\n\u001b[0;32m---> 76\u001b[0m ) \u001b[38;5;241m=\u001b[39m rational_quadratic_spline(\n\u001b[1;32m     77\u001b[0m     inputs\u001b[38;5;241m=\u001b[39minputs[inside_interval_mask],\n\u001b[1;32m     78\u001b[0m     unnormalized_widths\u001b[38;5;241m=\u001b[39munnormalized_widths[inside_interval_mask, :],\n\u001b[1;32m     79\u001b[0m     unnormalized_heights\u001b[38;5;241m=\u001b[39munnormalized_heights[inside_interval_mask, :],\n\u001b[1;32m     80\u001b[0m     unnormalized_derivatives\u001b[38;5;241m=\u001b[39munnormalized_derivatives_[inside_interval_mask, :],\n\u001b[1;32m     81\u001b[0m     inverse\u001b[38;5;241m=\u001b[39minverse,\n\u001b[1;32m     82\u001b[0m     left\u001b[38;5;241m=\u001b[39mleft,\n\u001b[1;32m     83\u001b[0m     right\u001b[38;5;241m=\u001b[39mright,\n\u001b[1;32m     84\u001b[0m     bottom\u001b[38;5;241m=\u001b[39mbottom,\n\u001b[1;32m     85\u001b[0m     top\u001b[38;5;241m=\u001b[39mtop,\n\u001b[1;32m     86\u001b[0m     min_bin_width\u001b[38;5;241m=\u001b[39mmin_bin_width,\n\u001b[1;32m     87\u001b[0m     min_bin_height\u001b[38;5;241m=\u001b[39mmin_bin_height,\n\u001b[1;32m     88\u001b[0m     min_derivative\u001b[38;5;241m=\u001b[39mmin_derivative,\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m outputs_masked\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mand\u001b[39;00m logabsdet\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m logabsdet_masked\u001b[38;5;241m.\u001b[39mdtype:\n\u001b[1;32m     91\u001b[0m     outputs[inside_interval_mask] \u001b[38;5;241m=\u001b[39m outputs_masked\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/normflows/utils/splines.py:181\u001b[0m, in \u001b[0;36mrational_quadratic_spline\u001b[0;34m(inputs, unnormalized_widths, unnormalized_heights, unnormalized_derivatives, inverse, left, right, bottom, top, min_bin_width, min_bin_height, min_derivative)\u001b[0m\n\u001b[1;32m    178\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39minput_delta \u001b[38;5;241m*\u001b[39m (inputs \u001b[38;5;241m-\u001b[39m input_cumheights)\n\u001b[1;32m    180\u001b[0m discriminant \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m a \u001b[38;5;241m*\u001b[39m c\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (discriminant \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    183\u001b[0m root \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m c) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m-\u001b[39mb \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(discriminant))\n\u001b[1;32m    184\u001b[0m outputs \u001b[38;5;241m=\u001b[39m root \u001b[38;5;241m*\u001b[39m input_bin_widths \u001b[38;5;241m+\u001b[39m input_cumwidths\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "waldo_stats_tractable_beta = compute_MAE_N_B(\n",
    "    kind = \"tractable\", \n",
    "    score = waldo_score, \n",
    "    theta_grid_eval = thetas_valid, \n",
    "    simulator = simulator, \n",
    "    prior = prior, \n",
    "    N = 5, \n",
    "    B = 10000, \n",
    "    B_valid = 300, \n",
    "    N_lambda = 150,\n",
    "    seed = 125,\n",
    "    K = 70,\n",
    "    n_estimators = 250,\n",
    "    min_samples_leaf = 250,\n",
    "    log_transf = False,\n",
    "    split_calib = False,\n",
    "    using_beta = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waldo_stats_tractable_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally, for e-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_value_stats_tractable_beta = compute_MAE_N_B(\n",
    "    kind = \"tractable\", \n",
    "    score = e_value_score, \n",
    "    theta_grid_eval = thetas_valid, \n",
    "    simulator = simulator, \n",
    "    prior = prior, \n",
    "    N = 5, \n",
    "    B = 10000, \n",
    "    B_valid = 300, \n",
    "    N_lambda = 150,\n",
    "    seed = 125,\n",
    "    K = 70,\n",
    "    n_estimators = 250,\n",
    "    min_samples_leaf = 250,\n",
    "    log_transf = False,\n",
    "    split_calib = False,\n",
    "    using_beta = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_value_stats_tractable_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing $n$ to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating for several $n$ and $B$:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
